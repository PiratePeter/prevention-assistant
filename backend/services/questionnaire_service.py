from dotenv import load_dotenv
from google import genai
import json

load_dotenv()
client = genai.Client()


def gen_questionaire_logic(risks: list[dict], previous_claims_description: str)-> list[str]:
    """
    Generates a questionnaire based on the provided risks and previous claims description.
    :param risks: List of risks with their names and danger levels
    :param previous_claims_description: Description of previous claims
    :return: List of questions generated by the LLM
    """
    merged_risks = ", ".join([f"{k} ({v})" for k, v in risks.items()])
    if previous_claims_description:
        merged_risks += f". When formulating questions concentrate on the domain of the previous claim(s): {previous_claims_description}."

    prompt = (
        "Generate a JSON-formatted questionnaire for buildings insurance in the canton of Bern, Switzerland."
        + " The questionnaire aims to gather information necessary to recommend preventative actions to the building owner,"
        + f" mitigating future damage from natural forces. Known risk levels for the building's location are: {merged_risks}."
        + " The questionnaire should be a JSON object with a single key, 'questions', whose value is a list of strings representing"
        + " the questions. Each question should be open-ended, designed to elicit free-text responses that provide valuable insights"
        + " into the building's condition, usage, and vulnerability to the identified risks. Prioritize questions that will be most"
        + " useful in formulating actionable recommendations for the building owner. Return only the 5 most relevant questions,"
        + f" tailored to the specific risk levels {merged_risks}, that will provide the most valuable insights for formulating"
        + " recommended actions. The questions should cover a range of relevant aspects related to building construction,"
        + " maintenance, and surrounding environment to best evaluate risks and recommend effective mitigation measures."
        + " Ensure the questions are in high german (minor adaptions to Switzerland ß->ss, etc.), clear, concise, and directly related"
        + " to the risks identified."
    )
    
    response = client.models.generate_content(
        model='gemini-2.5-flash', contents=prompt
    )

    response_json = response.text

    try:
        json.loads(response_json)
    except json.JSONDecodeError as e:
        raise ValueError(f"Response is not valid JSON: {response_json}") from e
    if not response_json.startswith('[') or not response_json.endswith(']'):
        raise ValueError(f"Response is not a list of questions: {response_json}")
    
    # Parse the response as JSON
    questions = json.loads(response.text)

    if not isinstance(questions, list):
        raise ValueError(f"Response is not a list of questions: {questions}")
    return questions


if __name__ == "__main__":
    # Example usage
    risks_example = {
        "Hochwasser": "hohe Gefährdung",
        "Sturm": "mittlere Gefährdung",
        "Hagel": "mittlere Gefährdung",
        "Lawine": "keine Gef\u00e4hrdung",
        "(Erd-)Rutschung": "keine Gefährdung"
    }
    previous_claims_example = "Previous claims related to flooding in 2020 where the basement was affected."
    
    try:
        questions = gen_questionaire_logic(risks_example, previous_claims_example)
        print("Generated Questions:", questions)
    except Exception as e:
        print(f"Error: {str(e)}")